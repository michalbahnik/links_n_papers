# Papers in 2023

These papers cought my attention in year 2023.

* [Poisoning Web-Scale Training Datasets is Practical](https://arxiv.org/abs/2302.10149)
  * Cheap and effective way how to poison models scraping web sources for training.
* [OneFormer: One Transformer to Rule Universal Image Segmentation](https://arxiv.org/abs/2211.06220v2)
  * Universal image segmentation trained at once and achieving SotA performance. 
* [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290v2)
  * DPO aims to solve RLHF problem with only a simple classification loss.
* [ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities](https://arxiv.org/abs/2305.11172v1)
  * General representation model with competitive performance on multiple ML tasks (vision, text, audio combinations).
* [Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution](https://arxiv.org/abs/2307.06304)
  * Adressing fixed aspect ratio and resolution problem of previous transformer architectures.
* [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377)
  * MAEs show strong capability to efficiently generalise vision concepts.
* [InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions](https://arxiv.org/abs/2211.05778v4)
  * Large-scale CNN-based foundation model with deformable convolutions competing with transformers.
