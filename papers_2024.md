# Papers in 2024

These papers cought my attention in year 2024.

* [TinyLlama: An Open-Source Small Language Model](https://paperswithcode.com/paper/tinyllama-an-open-source-small-language-model)
  * 1.1B LLM based on LLama 2 with great performance/size ratio.
* [Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch](https://paperswithcode.com/paper/language-models-are-super-mario-absorbing)
  * Merging different homologous models without training by delta parameter manipulationby DARE method.
* [OpenVoice: Versatile Instant Voice Cloning](https://paperswithcode.com/paper/openvoice-versatile-instant-voice-cloning)
  * Open-source voice cloning. Zero-shot ross-language.
* [Efficient Deformable ConvNets: Rethinking Dynamic and Sparse Operator for Vision Applications]()
  * Improving Deformable Convolution v4 (DCNv4) operator, addressing limitations of DCNv3 with improved dynamic property, expressive power, and memory optimization.
* [The boundary of neural network trainability is fractal](https://arxiv.org/abs/2402.06184v1)
  * Funny paper discovering fractals in neural network training.
* [Lag-Llama: Towards Foundation Models for Probabilistic Time Series Forecasting](https://paperswithcode.com/paper/lag-llama-towards-foundation-models-for-time)
  * Foundation model for univariate probabilistic time series forecasting based on a decoder-only transformer architecture that uses lags as covariates.
* [Learning to Fly in Seconds](https://paperswithcode.com/paper/learning-to-fly-in-seconds)
  * Asymmetric actor-critic-based architecture coupled with a highly reliable RL-based training paradigm for efficient end-to-end quadrotor control learning.
* [Scalable Diffusion Models with Transformers](https://paperswithcode.com/paper/scalable-diffusion-models-with-transformers)
  * Introducing Diffusion Transformers (DiT) by replacing U-Net backbone in Diffusion models with Visual Transformers.
* [World Model on Million-Length Video And Language With RingAttention](https://paperswithcode.com/paper/world-model-on-million-length-video-and)
  * Training LLMs on long videos and texts with high retrieval rate and 1M context length, introducing RingAttention.
* [Revisiting Feature Prediction for Learning Visual Representations from Video](https://paperswithcode.com/paper/revisiting-feature-prediction-for-learning)
  * Self-supervised visual feature prediction on videos aims to improve real world universal understanding.
* [GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection](https://arxiv.org/pdf/2403.03507v1.pdf)
  * Innovative full-parameter but memory efficient training strategy for LLMs.
* [TripoSR: Fast 3D Object Reconstruction from a Single Image](https://arxiv.org/abs/2403.02151)
  * Open-source (MIT) object reconstruction from a single (!) image.
* [Evolutionary Optimization of Model Merging Recipes](https://paperswithcode.com/paper/evolutionary-optimization-of-model-merging)
  * Effective cross-architecture LLM merging using evolutionary algorithms.
* [FeatUp: A Model-Agnostic Framework for Features at Any Resolution](https://paperswithcode.com/paper/featup-a-model-agnostic-framework-for)
  * Fast model-agnostic drop-in visual features upsampler.
* [LLM4Decompile: Decompiling Binary Code with Large Language Models](https://paperswithcode.com/paper/llm4decompile-decompiling-binary-code-with)
  * First open-source C code decompilation LLM and re-compilability and re-executability focused benchmark.
* [EasyJailbreak: A Unified Framework for Jailbreaking Large Language Models](https://paperswithcode.com/paper/easyjailbreak-a-unified-framework-for)
  * Framework for automatic jailbraking of LLMs with nice overview of jailbraking methods.
* [UniDepth: Universal Monocular Metric Depth Estimation](https://paperswithcode.com/paper/unidepth-universal-monocular-metric-depth)
  * Universal monocular depth estimation with strong zero-shot capability.  
* [LiDAR4D: Dynamic Neural Fields for Novel Space-time View LiDAR Synthesis](https://paperswithcode.com/paper/lidar4d-dynamic-neural-fields-for-novel-space)
  * Novel method to reconstruct scenes from lidar data using Neural Radience Fields.
